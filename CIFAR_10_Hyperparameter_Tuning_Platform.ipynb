{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhHsLXvEOoZ8",
        "outputId": "3ee855a7-eb81-4c8a-860a-0c78d3ee7580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: A100-SXM4-40GB (UUID: GPU-3d203e26-4a3e-3592-e586-3080f1d5b7dc)\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHKfnFKyHfIA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use('ggplot')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB569scbHfIh",
        "outputId": "e167147e-c7f4-48c9-90a9-75914c01c0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 15s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load Dataset - Data Augmentation\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Randomly Rotate/Flip Image To Prevent Overfitting\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Reshape Data and Convert To Floating Point\n",
        "img_rows, img_cols = 32, 32\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
        "input_shape = (img_rows, img_cols, 3)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalise Data\n",
        "x_test = (x_test - np.mean(x_train))/np.std(x_train)\n",
        "x_train = (x_train - np.mean(x_train))/np.std(x_train)\n",
        "\n",
        "# One-Hot Encoding Of Output Categories\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZDpJYCzHfJc"
      },
      "source": [
        "#### LeNet-5 Implementation For CIFAR-10\n",
        "ReLU Timing: 2 min 23.19s\n",
        "\n",
        "ReLU Accuracy: 0.6398\n",
        "\n",
        "ELU Timing: 2 min 23.56s\n",
        "\n",
        "ELU Accuracy: 0.6556\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlna7Jj2HfJd",
        "outputId": "dbcae69d-3a66-4bbe-86ca-38961c5b67fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Of LeNet Using ReLU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 14s 6ms/step - loss: 1.5086 - accuracy: 0.4547 - val_loss: 1.2888 - val_accuracy: 0.5398\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 1.2252 - accuracy: 0.5646 - val_loss: 1.2382 - val_accuracy: 0.5556\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 1.1029 - accuracy: 0.6123 - val_loss: 1.1754 - val_accuracy: 0.5918\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 1.0220 - accuracy: 0.6389 - val_loss: 1.0421 - val_accuracy: 0.6414\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.9546 - accuracy: 0.6636 - val_loss: 1.0854 - val_accuracy: 0.6242\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.8994 - accuracy: 0.6850 - val_loss: 1.0140 - val_accuracy: 0.6524\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.8622 - accuracy: 0.6961 - val_loss: 1.0069 - val_accuracy: 0.6538\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.8172 - accuracy: 0.7107 - val_loss: 1.0210 - val_accuracy: 0.6508\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.7862 - accuracy: 0.7210 - val_loss: 1.0036 - val_accuracy: 0.6558\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.7575 - accuracy: 0.7312 - val_loss: 1.0123 - val_accuracy: 0.6618\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 4s 6ms/step - loss: 0.7190 - accuracy: 0.7462 - val_loss: 1.0166 - val_accuracy: 0.6662\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.6927 - accuracy: 0.7555 - val_loss: 1.0519 - val_accuracy: 0.6674\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.6707 - accuracy: 0.7601 - val_loss: 1.0448 - val_accuracy: 0.6674\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.6434 - accuracy: 0.7724 - val_loss: 1.0802 - val_accuracy: 0.6654\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.6202 - accuracy: 0.7780 - val_loss: 1.0975 - val_accuracy: 0.6526\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5945 - accuracy: 0.7899 - val_loss: 1.1241 - val_accuracy: 0.6642\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5820 - accuracy: 0.7934 - val_loss: 1.1467 - val_accuracy: 0.6456\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5629 - accuracy: 0.7996 - val_loss: 1.1896 - val_accuracy: 0.6430\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5343 - accuracy: 0.8090 - val_loss: 1.2011 - val_accuracy: 0.6434\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5205 - accuracy: 0.8111 - val_loss: 1.2553 - val_accuracy: 0.6460\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5025 - accuracy: 0.8201 - val_loss: 1.2502 - val_accuracy: 0.6494\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.4886 - accuracy: 0.8231 - val_loss: 1.3163 - val_accuracy: 0.6392\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.4712 - accuracy: 0.8306 - val_loss: 1.3718 - val_accuracy: 0.6426\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.4605 - accuracy: 0.8330 - val_loss: 1.4131 - val_accuracy: 0.6394\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.4404 - accuracy: 0.8415 - val_loss: 1.4218 - val_accuracy: 0.6340\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 4s 6ms/step - loss: 0.4242 - accuracy: 0.8467 - val_loss: 1.5052 - val_accuracy: 0.6348\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.4133 - accuracy: 0.8491 - val_loss: 1.5241 - val_accuracy: 0.6324\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.3979 - accuracy: 0.8567 - val_loss: 1.5972 - val_accuracy: 0.6284\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 0.3909 - accuracy: 0.8586 - val_loss: 1.5664 - val_accuracy: 0.6316\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.3836 - accuracy: 0.8598 - val_loss: 1.6039 - val_accuracy: 0.6398\n",
            "Training Time For LeNet Using ReLU: 0:02:23.192448\n",
            "Training Of LeNet Using ELU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 1.5043 - accuracy: 0.4630 - val_loss: 1.3861 - val_accuracy: 0.5096\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 1.2611 - accuracy: 0.5544 - val_loss: 1.2378 - val_accuracy: 0.5626\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 1.1544 - accuracy: 0.5936 - val_loss: 1.1196 - val_accuracy: 0.5996\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 4s 5ms/step - loss: 1.0728 - accuracy: 0.6226 - val_loss: 1.0848 - val_accuracy: 0.6148\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 1.0042 - accuracy: 0.6448 - val_loss: 1.0549 - val_accuracy: 0.6294\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.9392 - accuracy: 0.6703 - val_loss: 0.9725 - val_accuracy: 0.6626\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.8817 - accuracy: 0.6891 - val_loss: 1.0210 - val_accuracy: 0.6478\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.8319 - accuracy: 0.7069 - val_loss: 0.9516 - val_accuracy: 0.6748\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.7839 - accuracy: 0.7254 - val_loss: 0.9316 - val_accuracy: 0.6758\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.7424 - accuracy: 0.7391 - val_loss: 0.9440 - val_accuracy: 0.6818\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.7001 - accuracy: 0.7534 - val_loss: 0.9493 - val_accuracy: 0.6836\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.6655 - accuracy: 0.7662 - val_loss: 0.9407 - val_accuracy: 0.6854\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.6236 - accuracy: 0.7786 - val_loss: 0.9788 - val_accuracy: 0.6894\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5905 - accuracy: 0.7926 - val_loss: 0.9913 - val_accuracy: 0.6906\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5557 - accuracy: 0.8041 - val_loss: 1.0298 - val_accuracy: 0.6838\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.5221 - accuracy: 0.8140 - val_loss: 1.0958 - val_accuracy: 0.6748\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.4917 - accuracy: 0.8264 - val_loss: 1.1163 - val_accuracy: 0.6784\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.4618 - accuracy: 0.8350 - val_loss: 1.1581 - val_accuracy: 0.6740\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.4374 - accuracy: 0.8437 - val_loss: 1.1933 - val_accuracy: 0.6788\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.4112 - accuracy: 0.8524 - val_loss: 1.2545 - val_accuracy: 0.6692\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.3942 - accuracy: 0.8581 - val_loss: 1.3168 - val_accuracy: 0.6670\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.3674 - accuracy: 0.8676 - val_loss: 1.3779 - val_accuracy: 0.6526\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.3503 - accuracy: 0.8738 - val_loss: 1.4903 - val_accuracy: 0.6576\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.3299 - accuracy: 0.8826 - val_loss: 1.5007 - val_accuracy: 0.6602\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.3132 - accuracy: 0.8871 - val_loss: 1.5753 - val_accuracy: 0.6598\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.2958 - accuracy: 0.8930 - val_loss: 1.5888 - val_accuracy: 0.6574\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.2807 - accuracy: 0.8990 - val_loss: 1.7345 - val_accuracy: 0.6556\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.2727 - accuracy: 0.9014 - val_loss: 1.7698 - val_accuracy: 0.6518\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.2528 - accuracy: 0.9070 - val_loss: 1.8627 - val_accuracy: 0.6576\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 3s 5ms/step - loss: 0.2442 - accuracy: 0.9099 - val_loss: 1.9201 - val_accuracy: 0.6556\n",
            "Training Time For LeNet Using ELU: 0:02:23.562284\n"
          ]
        }
      ],
      "source": [
        "class LeNet:\n",
        "  def __init__(self, inputShape=(32,32,3), activationFunction='elu'):\n",
        "    self.inputShape = inputShape\n",
        "    self.activationFunction = activationFunction\n",
        "\n",
        "  def buildModel(self):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(6, kernel_size=(5,5), strides=(1,1), padding='same', input_shape=input_shape, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros'))\n",
        "\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(16, kernel_size=(5,5), padding='valid'))\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(120, kernel_size=(5,5), padding='valid'))\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(84))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(num_classes))\n",
        "\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "    return model\n",
        "\n",
        "LeNetInstance = LeNet(activationFunction = 'relu')\n",
        "LeNetReluModel = LeNetInstance.buildModel()\n",
        "LeNetReluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "LeNetInstance = LeNet(activationFunction = 'elu')\n",
        "LeNetEluModel = LeNetInstance.buildModel()\n",
        "LeNetEluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of LeNet Using ReLU Activation Function\")\n",
        "LeNetReluModelLog = LeNetReluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For LeNet Using ReLU: %s' % (datetime.datetime.now() - startTime))\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of LeNet Using ELU Activation Function\")\n",
        "LeNetEluModelLog = LeNetEluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For LeNet Using ELU: %s' % (datetime.datetime.now() - startTime))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnVETOhRUuA"
      },
      "source": [
        "#### ResNet-50 Implementation For CIFAR-10 (Using Colab Pro)\n",
        "ReLU Timing: 36 min 43.61s\n",
        "\n",
        "ReLU Accuracy: 0.8298\n",
        "\n",
        "ELU Timing: 37 min 32.61s\n",
        "\n",
        "ELU Accuracy: 0.8176"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amkfcVDuFTOU",
        "outputId": "9c00d2f5-68c8-4029-cf17-3ef5d022a0dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Of ResNet-50 Using ReLU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 81s 106ms/step - loss: 1.8039 - accuracy: 0.4259 - val_loss: 1.8303 - val_accuracy: 0.4422\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 1.0960 - accuracy: 0.6136 - val_loss: 0.9422 - val_accuracy: 0.6654\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.8331 - accuracy: 0.7085 - val_loss: 0.8848 - val_accuracy: 0.7062\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.6544 - accuracy: 0.7722 - val_loss: 0.6991 - val_accuracy: 0.7618\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.5307 - accuracy: 0.8155 - val_loss: 0.8091 - val_accuracy: 0.7406\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.4398 - accuracy: 0.8462 - val_loss: 0.6377 - val_accuracy: 0.7834\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.3404 - accuracy: 0.8816 - val_loss: 0.8976 - val_accuracy: 0.7382\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.2586 - accuracy: 0.9090 - val_loss: 0.6164 - val_accuracy: 0.8100\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.1900 - accuracy: 0.9347 - val_loss: 0.7914 - val_accuracy: 0.7884\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.1408 - accuracy: 0.9507 - val_loss: 0.8579 - val_accuracy: 0.7966\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.1255 - accuracy: 0.9562 - val_loss: 0.7247 - val_accuracy: 0.8160\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.1077 - accuracy: 0.9626 - val_loss: 0.7717 - val_accuracy: 0.8078\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.0987 - accuracy: 0.9665 - val_loss: 0.9221 - val_accuracy: 0.8012\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.0707 - accuracy: 0.9765 - val_loss: 0.8182 - val_accuracy: 0.8084\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.0849 - accuracy: 0.9717 - val_loss: 0.8853 - val_accuracy: 0.8160\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.0576 - accuracy: 0.9802 - val_loss: 0.8940 - val_accuracy: 0.8116\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.0573 - accuracy: 0.9805 - val_loss: 0.9950 - val_accuracy: 0.7922\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0481 - accuracy: 0.9837 - val_loss: 1.0201 - val_accuracy: 0.8016\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.0448 - accuracy: 0.9843 - val_loss: 1.0155 - val_accuracy: 0.8004\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.0514 - accuracy: 0.9821 - val_loss: 1.0102 - val_accuracy: 0.8086\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.0371 - accuracy: 0.9868 - val_loss: 1.0748 - val_accuracy: 0.8108\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0354 - accuracy: 0.9874 - val_loss: 1.1127 - val_accuracy: 0.8024\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.9860 - val_accuracy: 0.8182\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.0422 - accuracy: 0.9855 - val_loss: 0.9440 - val_accuracy: 0.8222\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 1.1081 - val_accuracy: 0.8142\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0285 - accuracy: 0.9896 - val_loss: 1.0099 - val_accuracy: 0.8262\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0249 - accuracy: 0.9913 - val_loss: 1.0239 - val_accuracy: 0.8216\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0319 - accuracy: 0.9887 - val_loss: 1.1323 - val_accuracy: 0.8088\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 73s 104ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 1.1775 - val_accuracy: 0.7972\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 73s 103ms/step - loss: 0.0259 - accuracy: 0.9910 - val_loss: 1.1144 - val_accuracy: 0.8298\n",
            "Training Time For ResNet-50 Using ReLU: 0:36:43.612650\n",
            "Training Of ResNet-50 Using ELU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 81s 108ms/step - loss: 2.0711 - accuracy: 0.4276 - val_loss: 1.5726 - val_accuracy: 0.4842\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 75s 106ms/step - loss: 1.1005 - accuracy: 0.6164 - val_loss: 1.2569 - val_accuracy: 0.6010\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 75s 106ms/step - loss: 0.8812 - accuracy: 0.6926 - val_loss: 1.2150 - val_accuracy: 0.6196\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 75s 106ms/step - loss: 0.7759 - accuracy: 0.7299 - val_loss: 1.4066 - val_accuracy: 0.6032\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.6966 - accuracy: 0.7598 - val_loss: 1.1622 - val_accuracy: 0.6504\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 75s 106ms/step - loss: 0.6184 - accuracy: 0.7863 - val_loss: 0.9145 - val_accuracy: 0.7080\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.5558 - accuracy: 0.8075 - val_loss: 0.8000 - val_accuracy: 0.7604\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.4966 - accuracy: 0.8266 - val_loss: 0.7524 - val_accuracy: 0.7678\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.4481 - accuracy: 0.8424 - val_loss: 0.7522 - val_accuracy: 0.7660\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.3727 - accuracy: 0.8705 - val_loss: 0.8040 - val_accuracy: 0.7696\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.3234 - accuracy: 0.8864 - val_loss: 0.8047 - val_accuracy: 0.7730\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 75s 106ms/step - loss: 0.2720 - accuracy: 0.9036 - val_loss: 0.8401 - val_accuracy: 0.7842\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.2103 - accuracy: 0.9250 - val_loss: 0.7462 - val_accuracy: 0.8064\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.1795 - accuracy: 0.9365 - val_loss: 0.8315 - val_accuracy: 0.8042\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.1532 - accuracy: 0.9461 - val_loss: 0.8742 - val_accuracy: 0.8046\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 74s 105ms/step - loss: 0.1254 - accuracy: 0.9570 - val_loss: 0.9768 - val_accuracy: 0.7952\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.1151 - accuracy: 0.9598 - val_loss: 0.9163 - val_accuracy: 0.8130\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.1094 - accuracy: 0.9623 - val_loss: 0.9679 - val_accuracy: 0.8004\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.0929 - accuracy: 0.9680 - val_loss: 1.1742 - val_accuracy: 0.7898\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 74s 106ms/step - loss: 0.0841 - accuracy: 0.9710 - val_loss: 1.1210 - val_accuracy: 0.8060\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 75s 106ms/step - loss: 0.0859 - accuracy: 0.9716 - val_loss: 1.2074 - val_accuracy: 0.7972\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 75s 106ms/step - loss: 0.0690 - accuracy: 0.9764 - val_loss: 1.0929 - val_accuracy: 0.8154\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 76s 108ms/step - loss: 0.0710 - accuracy: 0.9760 - val_loss: 1.2151 - val_accuracy: 0.8012\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 76s 108ms/step - loss: 0.0578 - accuracy: 0.9807 - val_loss: 1.1776 - val_accuracy: 0.8062\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 76s 108ms/step - loss: 0.0653 - accuracy: 0.9780 - val_loss: 1.2447 - val_accuracy: 0.8082\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 76s 108ms/step - loss: 0.0646 - accuracy: 0.9788 - val_loss: 1.2692 - val_accuracy: 0.8024\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 76s 108ms/step - loss: 0.0583 - accuracy: 0.9806 - val_loss: 1.2420 - val_accuracy: 0.8064\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 76s 108ms/step - loss: 0.0558 - accuracy: 0.9814 - val_loss: 1.2454 - val_accuracy: 0.8180\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 76s 108ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 1.2206 - val_accuracy: 0.8204\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 75s 107ms/step - loss: 0.0511 - accuracy: 0.9835 - val_loss: 1.2423 - val_accuracy: 0.8176\n",
            "Training Time For ResNet-50 Using ELU: 0:37:32.616402\n"
          ]
        }
      ],
      "source": [
        "class ResNet50:\n",
        "  def __init__(self, activationFunction='relu'):\n",
        "    self.activationFunction = activationFunction\n",
        "\n",
        "  def convolutionalBlock(self, X, f, filters, s = 2):\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "    X = tf.keras.layers.Conv2D(F1, (1, 1), strides = (s,s), kernel_initializer = \"glorot_uniform\")(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\")(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = \"glorot_uniform\")(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X_shortcut = tf.keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', kernel_initializer = \"glorot_uniform\")(X_shortcut)\n",
        "    X_shortcut = tf.keras.layers.BatchNormalization(axis = 3)(X_shortcut)\n",
        "    X = tf.keras.layers.Add()([X_shortcut, X])\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    return X\n",
        "\n",
        "  def identityBlock(self, X, f, filters):\n",
        "    F1, F2, F3 = filters\n",
        "    X_shortcut = X\n",
        "    X = tf.keras.layers.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = \"glorot_uniform\")(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\")(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', kernel_initializer = \"glorot_uniform\")(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Add()([X_shortcut, X])\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    return X\n",
        "\n",
        "  def buildModel(self, classes=10):\n",
        "    X_input = tf.keras.layers.Input(input_shape)\n",
        "    X = tf.keras.layers.Resizing(224, 224)(X_input)\n",
        "    X = tf.keras.layers.ZeroPadding2D((3, 3))(X)\n",
        "    X = tf.keras.layers.Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = \"glorot_uniform\")(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = [64, 64, 256], s = 1)\n",
        "    X = self.identityBlock(X, 3, [64, 64, 256])\n",
        "    X = self.identityBlock(X, 3, [64, 64, 256])\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = [128, 128, 512], s = 2)\n",
        "    X = self.identityBlock(X, 3, [128, 128, 512])\n",
        "    X = self.identityBlock(X, 3, [128, 128, 512])\n",
        "    X = self.identityBlock(X, 3, [128, 128, 512])\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
        "    X = self.identityBlock(X, 3, [256, 256, 1024])\n",
        "    X = self.identityBlock(X, 3, [256, 256, 1024])\n",
        "    X = self.identityBlock(X, 3, [256, 256, 1024])\n",
        "    X = self.identityBlock(X, 3, [256, 256, 1024])\n",
        "    X = self.identityBlock(X, 3, [256, 256, 1024])\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
        "    X = self.identityBlock(X, 3, [512, 512, 2048])\n",
        "    X = self.identityBlock(X, 3, [512, 512, 2048])\n",
        "    X = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(X)\n",
        "    X = tf.keras.layers.Flatten()(X)\n",
        "    X = tf.keras.layers.Dense(classes, activation='softmax', kernel_initializer = \"glorot_uniform\")(X)\n",
        "    model = tf.keras.Model(inputs = X_input, outputs = X)\n",
        "    return model\n",
        "\n",
        "ResInstance = ResNet50(activationFunction = 'relu')\n",
        "ResnetReluModel = ResInstance.buildModel()\n",
        "ResnetReluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "ResInstance = ResNet50(activationFunction = 'elu')\n",
        "ResnetEluModel = ResInstance.buildModel()\n",
        "ResnetEluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of ResNet-50 Using ReLU Activation Function\")\n",
        "model_log = ResnetReluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For ResNet-50 Using ReLU: %s' % (datetime.datetime.now() - startTime))\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of ResNet-50 Using ELU Activation Function\")\n",
        "model_log = ResnetEluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "\n",
        "print('Training Time For ResNet-50 Using ELU: %s' % (datetime.datetime.now() - startTime))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXocNuc3EOTz"
      },
      "source": [
        "#### ResNet-34 For CIFAR-10 (Using Colab Pro)\n",
        "ReLU Timing: 22 min 52.96s\n",
        "\n",
        "ReLU Accuracy: 0.8270\n",
        "\n",
        "ELU Timing: 23 min 01.17s\n",
        "\n",
        "ELU Accuracy: 0.8232"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8mciVEZCL7a",
        "outputId": "e15f761e-3471-4869-978f-b358575b8ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Of ResNet-34 Using ReLU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 54s 65ms/step - loss: 2.6083 - accuracy: 0.3031 - val_loss: 1.8964 - val_accuracy: 0.3858\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 1.7075 - accuracy: 0.4478 - val_loss: 1.5910 - val_accuracy: 0.4870\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 1.4052 - accuracy: 0.5440 - val_loss: 1.3202 - val_accuracy: 0.5662\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 1.1750 - accuracy: 0.6238 - val_loss: 1.3600 - val_accuracy: 0.5782\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.9876 - accuracy: 0.6870 - val_loss: 0.9872 - val_accuracy: 0.6834\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 44s 63ms/step - loss: 0.8155 - accuracy: 0.7450 - val_loss: 0.8947 - val_accuracy: 0.7066\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.6786 - accuracy: 0.7901 - val_loss: 0.9900 - val_accuracy: 0.6932\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.5599 - accuracy: 0.8284 - val_loss: 0.7003 - val_accuracy: 0.7882\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.4605 - accuracy: 0.8609 - val_loss: 0.7142 - val_accuracy: 0.7834\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.3704 - accuracy: 0.8918 - val_loss: 0.6742 - val_accuracy: 0.8076\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.2915 - accuracy: 0.9198 - val_loss: 0.7076 - val_accuracy: 0.7994\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.2251 - accuracy: 0.9416 - val_loss: 0.7126 - val_accuracy: 0.8108\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.1679 - accuracy: 0.9610 - val_loss: 0.7476 - val_accuracy: 0.8106\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.1363 - accuracy: 0.9713 - val_loss: 0.7591 - val_accuracy: 0.8170\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.1000 - accuracy: 0.9821 - val_loss: 0.9063 - val_accuracy: 0.7978\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0888 - accuracy: 0.9847 - val_loss: 0.7854 - val_accuracy: 0.8226\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0663 - accuracy: 0.9915 - val_loss: 0.8476 - val_accuracy: 0.8196\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0693 - accuracy: 0.9891 - val_loss: 0.8306 - val_accuracy: 0.8250\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0509 - accuracy: 0.9948 - val_loss: 0.8473 - val_accuracy: 0.8262\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0539 - accuracy: 0.9930 - val_loss: 0.8290 - val_accuracy: 0.8290\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0459 - accuracy: 0.9951 - val_loss: 0.9684 - val_accuracy: 0.8138\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.0431 - accuracy: 0.9956 - val_loss: 0.8840 - val_accuracy: 0.8272\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0411 - accuracy: 0.9960 - val_loss: 0.9319 - val_accuracy: 0.8220\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0405 - accuracy: 0.9959 - val_loss: 0.9462 - val_accuracy: 0.8252\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0346 - accuracy: 0.9972 - val_loss: 1.0058 - val_accuracy: 0.8120\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.0332 - accuracy: 0.9975 - val_loss: 0.9700 - val_accuracy: 0.8262\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.0342 - accuracy: 0.9972 - val_loss: 0.9402 - val_accuracy: 0.8268\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.0310 - accuracy: 0.9979 - val_loss: 0.9563 - val_accuracy: 0.8308\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.0288 - accuracy: 0.9979 - val_loss: 0.9398 - val_accuracy: 0.8316\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.0283 - accuracy: 0.9982 - val_loss: 0.9721 - val_accuracy: 0.8270\n",
            "Training Time For ResNet-34 Using ReLU: 0:22:52.962625\n",
            "Training Of ResNet-34 Using ELU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 53s 65ms/step - loss: 2.7246 - accuracy: 0.2860 - val_loss: 1.9710 - val_accuracy: 0.3406\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 1.7321 - accuracy: 0.4289 - val_loss: 1.7172 - val_accuracy: 0.4368\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 1.4602 - accuracy: 0.5210 - val_loss: 1.4241 - val_accuracy: 0.5220\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 1.2424 - accuracy: 0.5960 - val_loss: 1.3451 - val_accuracy: 0.5614\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 1.0704 - accuracy: 0.6549 - val_loss: 1.1264 - val_accuracy: 0.6324\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.9133 - accuracy: 0.7031 - val_loss: 0.8941 - val_accuracy: 0.7014\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.7969 - accuracy: 0.7430 - val_loss: 0.8783 - val_accuracy: 0.7234\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.6894 - accuracy: 0.7779 - val_loss: 0.8095 - val_accuracy: 0.7368\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.6109 - accuracy: 0.8054 - val_loss: 0.7156 - val_accuracy: 0.7718\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.5400 - accuracy: 0.8289 - val_loss: 0.6342 - val_accuracy: 0.7978\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.4784 - accuracy: 0.8492 - val_loss: 0.7888 - val_accuracy: 0.7472\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.4276 - accuracy: 0.8667 - val_loss: 0.6776 - val_accuracy: 0.7860\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.3788 - accuracy: 0.8828 - val_loss: 0.6638 - val_accuracy: 0.7888\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.3307 - accuracy: 0.8985 - val_loss: 0.6310 - val_accuracy: 0.8040\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.2898 - accuracy: 0.9141 - val_loss: 0.6478 - val_accuracy: 0.8144\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.2550 - accuracy: 0.9253 - val_loss: 0.6408 - val_accuracy: 0.8094\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.2111 - accuracy: 0.9397 - val_loss: 0.6247 - val_accuracy: 0.8220\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.1854 - accuracy: 0.9496 - val_loss: 0.6629 - val_accuracy: 0.8150\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.1557 - accuracy: 0.9607 - val_loss: 0.6840 - val_accuracy: 0.8214\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.1320 - accuracy: 0.9698 - val_loss: 0.6863 - val_accuracy: 0.8250\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.1148 - accuracy: 0.9743 - val_loss: 0.7334 - val_accuracy: 0.8114\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 45s 64ms/step - loss: 0.0939 - accuracy: 0.9815 - val_loss: 0.8189 - val_accuracy: 0.8104\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0836 - accuracy: 0.9842 - val_loss: 0.8007 - val_accuracy: 0.8162\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0719 - accuracy: 0.9884 - val_loss: 0.7910 - val_accuracy: 0.8194\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0643 - accuracy: 0.9908 - val_loss: 0.9117 - val_accuracy: 0.7998\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0573 - accuracy: 0.9922 - val_loss: 0.8196 - val_accuracy: 0.8260\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0494 - accuracy: 0.9947 - val_loss: 0.8893 - val_accuracy: 0.8132\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0501 - accuracy: 0.9935 - val_loss: 0.8922 - val_accuracy: 0.8084\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0464 - accuracy: 0.9950 - val_loss: 0.8725 - val_accuracy: 0.8204\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 46s 65ms/step - loss: 0.0401 - accuracy: 0.9965 - val_loss: 0.8724 - val_accuracy: 0.8232\n",
            "Training Time For ResNet-34 Using ELU: 0:23:01.175216\n"
          ]
        }
      ],
      "source": [
        "class ResNetImproved:\n",
        "  def __init__(self, activationFunction='relu'):\n",
        "    self.activationFunction = activationFunction\n",
        "\n",
        "  def convolutionalBlock(self, X, f, filters, s = 2):\n",
        "    X_shortcut = X\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (s,s), kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X_shortcut = tf.keras.layers.Conv2D(filters, (f, f), strides = (s,s), padding = 'valid', kernel_initializer = \"glorot_uniform\",)(X_shortcut)\n",
        "    X_shortcut = tf.keras.layers.BatchNormalization(axis = 3)(X_shortcut)\n",
        "    X = tf.keras.layers.Add()([X_shortcut, X])\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    return X\n",
        "\n",
        "  def identityBlock(self, X, f, filters):\n",
        "    X_shortcut = X\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Add()([X_shortcut, X])\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    return X\n",
        "\n",
        "  def buildModel(self, classes=10):\n",
        "    X_input = tf.keras.layers.Input(input_shape)\n",
        "    X = tf.keras.layers.Resizing(224, 224)(X_input)\n",
        "    X = tf.keras.layers.ZeroPadding2D((3, 3))(X)\n",
        "    X = tf.keras.layers.Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = \"glorot_uniform\",\n",
        "                               kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                         bias_regularizer=tf.keras.regularizers.L2(1e-4),\n",
        "                                         activity_regularizer=tf.keras.regularizers.L2(1e-5))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 64, s = 1)\n",
        "    X = self.identityBlock(X, 3, 64)\n",
        "    X = self.identityBlock(X, 3, 64)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 128, s = 2)\n",
        "    X = self.identityBlock(X, 3, 128)\n",
        "    X = self.identityBlock(X, 3, 128)\n",
        "    X = self.identityBlock(X, 3, 128)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 256, s = 2)\n",
        "    X = self.identityBlock(X, 3, 256)\n",
        "    X = self.identityBlock(X, 3, 256)\n",
        "    X = self.identityBlock(X, 3, 256)\n",
        "    X = self.identityBlock(X, 3, 256)\n",
        "    X = self.identityBlock(X, 3, 256)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 512, s = 2)\n",
        "    X = self.identityBlock(X, 3, 512)\n",
        "    X = self.identityBlock(X, 3, 512)\n",
        "    X = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(X)\n",
        "    X = tf.keras.layers.Flatten()(X)\n",
        "    X = tf.keras.layers.Dense(classes, activation='softmax', kernel_initializer = \"glorot_uniform\",\n",
        "                              kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                         bias_regularizer=tf.keras.regularizers.L2(1e-4),\n",
        "                                         activity_regularizer=tf.keras.regularizers.L2(1e-5))(X)\n",
        "    model = tf.keras.Model(inputs = X_input, outputs = X)\n",
        "    return model\n",
        "\n",
        "\n",
        "ResInstance = ResNetImproved(activationFunction = 'relu')\n",
        "ResnetReluModel = ResInstance.buildModel()\n",
        "ResnetReluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm = 1, decay=0.005), metrics=['accuracy'])\n",
        "\n",
        "ResInstance = ResNetImproved(activationFunction = 'elu')\n",
        "ResnetEluModel = ResInstance.buildModel()\n",
        "ResnetEluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm = 1, decay=0.005), metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of ResNet-34 Using ReLU Activation Function\")\n",
        "model_log = ResnetReluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For ResNet-34 Using ReLU: %s' % (datetime.datetime.now() - startTime))\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of ResNet-34 Using ELU Activation Function\")\n",
        "model_log = ResnetEluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "\n",
        "print('Training Time For ResNet-34 Using ELU: %s' % (datetime.datetime.now() - startTime))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNet 18 (Best Model) (No Colab Pro)\n",
        "\n",
        "ReLU Timing: 1h 21min 27.45s\n",
        "\n",
        "ReLU Timing (Adjusted To Colab Pro): 22 min 23.95s\n",
        "\n",
        "*(A100 is 1.47x faster than V100, which is 2.46x faster than T4)*\n",
        "\n",
        "ReLU Accuracy: 0.8310\n"
      ],
      "metadata": {
        "id": "h1id5ID_RMaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetImproved:\n",
        "  def __init__(self, activationFunction='relu'):\n",
        "    self.activationFunction = activationFunction\n",
        "\n",
        "  def convolutionalBlock(self, X, f, filters, s = 2):\n",
        "    X_shortcut = X\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (s,s), kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X_shortcut = tf.keras.layers.Conv2D(filters, (f, f), strides = (s,s), padding = 'valid', kernel_initializer = \"glorot_uniform\",)(X_shortcut)\n",
        "    X_shortcut = tf.keras.layers.BatchNormalization(axis = 3)(X_shortcut)\n",
        "    X = tf.keras.layers.Add()([X_shortcut, X])\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    return X\n",
        "\n",
        "  def identityBlock(self, X, f, filters):\n",
        "    X_shortcut = X\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.Conv2D(filters, (f, f), strides = (1,1), padding = 'same', kernel_initializer = \"glorot_uniform\",)(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Add()([X_shortcut, X])\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    return X\n",
        "\n",
        "  def buildModel(self, classes=10):\n",
        "    X_input = tf.keras.layers.Input(input_shape)\n",
        "    X = tf.keras.layers.Resizing(224, 224)(X_input)\n",
        "    X = tf.keras.layers.ZeroPadding2D((3, 3))(X)\n",
        "    X = tf.keras.layers.Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = \"glorot_uniform\",\n",
        "                               kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                         bias_regularizer=tf.keras.regularizers.L2(1e-4),\n",
        "                                         activity_regularizer=tf.keras.regularizers.L2(1e-5))(X)\n",
        "    X = tf.keras.layers.BatchNormalization(axis = 3)(X)\n",
        "    X = tf.keras.layers.Activation(self.activationFunction)(X)\n",
        "    X = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 64, s = 1)\n",
        "    X = self.identityBlock(X, 3, 64)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 128, s = 2)\n",
        "    X = self.identityBlock(X, 3, 128)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 256, s = 2)\n",
        "    X = self.identityBlock(X, 3, 256)\n",
        "    X = self.convolutionalBlock(X, f = 3, filters = 512, s = 2)\n",
        "    X = self.identityBlock(X, 3, 512)\n",
        "    X = tf.keras.layers.AveragePooling2D(pool_size=(2, 2))(X)\n",
        "    X = tf.keras.layers.Flatten()(X)\n",
        "    X = tf.keras.layers.Dense(classes, activation='softmax', kernel_initializer = \"glorot_uniform\",\n",
        "                              kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "                                         bias_regularizer=tf.keras.regularizers.L2(1e-4),\n",
        "                                         activity_regularizer=tf.keras.regularizers.L2(1e-5))(X)\n",
        "    model = tf.keras.Model(inputs = X_input, outputs = X)\n",
        "    return model\n",
        "\n",
        "\n",
        "ResInstance = ResNetImproved(activationFunction = 'relu')\n",
        "ResnetReluModel = ResInstance.buildModel()\n",
        "ResnetReluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm = 1, decay=0.005), metrics=['accuracy'])\n",
        "\n",
        "ResInstance = ResNetImproved(activationFunction = 'elu')\n",
        "ResnetEluModel = ResInstance.buildModel()\n",
        "ResnetEluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm = 1, decay=0.005), metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of ResNet-18 Using ReLU Activation Function\")\n",
        "model_log = ResnetReluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For ResNet-18 Using ReLU: %s' % (datetime.datetime.now() - startTime))\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of ResNet-18 Using ELU Activation Function\")\n",
        "model_log = ResnetEluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "\n",
        "print('Training Time For ResNet-18 Using ELU: %s' % (datetime.datetime.now() - startTime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sr2Kxk_vRGov",
        "outputId": "6b9f4113-dd14-42f3-8d49-f256b734c0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Of ResNet-18 Using ReLU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 176s 231ms/step - loss: 2.3503 - accuracy: 0.3366 - val_loss: 1.8313 - val_accuracy: 0.4364\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 161s 229ms/step - loss: 1.5643 - accuracy: 0.5030 - val_loss: 1.4340 - val_accuracy: 0.5600\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 161s 229ms/step - loss: 1.2164 - accuracy: 0.6212 - val_loss: 1.0940 - val_accuracy: 0.6554\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 162s 229ms/step - loss: 0.9496 - accuracy: 0.7069 - val_loss: 0.8690 - val_accuracy: 0.7364\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 161s 229ms/step - loss: 0.7457 - accuracy: 0.7746 - val_loss: 0.7912 - val_accuracy: 0.7562\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 161s 229ms/step - loss: 0.5910 - accuracy: 0.8258 - val_loss: 0.6861 - val_accuracy: 0.7854\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.4610 - accuracy: 0.8664 - val_loss: 0.6695 - val_accuracy: 0.8006\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.3597 - accuracy: 0.9016 - val_loss: 0.7298 - val_accuracy: 0.7844\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 161s 229ms/step - loss: 0.2648 - accuracy: 0.9340 - val_loss: 0.6556 - val_accuracy: 0.8120\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 161s 229ms/step - loss: 0.1899 - accuracy: 0.9596 - val_loss: 0.6890 - val_accuracy: 0.8132\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.1388 - accuracy: 0.9756 - val_loss: 0.7402 - val_accuracy: 0.8098\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.1002 - accuracy: 0.9870 - val_loss: 0.7093 - val_accuracy: 0.8290\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0837 - accuracy: 0.9906 - val_loss: 0.7792 - val_accuracy: 0.8190\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0668 - accuracy: 0.9940 - val_loss: 0.7842 - val_accuracy: 0.8176\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0594 - accuracy: 0.9954 - val_loss: 0.8212 - val_accuracy: 0.8162\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0575 - accuracy: 0.9954 - val_loss: 0.8096 - val_accuracy: 0.8196\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0485 - accuracy: 0.9973 - val_loss: 0.8459 - val_accuracy: 0.8220\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0448 - accuracy: 0.9978 - val_loss: 0.8295 - val_accuracy: 0.8264\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0401 - accuracy: 0.9984 - val_loss: 0.9067 - val_accuracy: 0.8172\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0430 - accuracy: 0.9975 - val_loss: 0.8567 - val_accuracy: 0.8180\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0353 - accuracy: 0.9991 - val_loss: 0.9017 - val_accuracy: 0.8214\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0349 - accuracy: 0.9989 - val_loss: 0.9645 - val_accuracy: 0.8032\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0367 - accuracy: 0.9982 - val_loss: 0.8704 - val_accuracy: 0.8324\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0316 - accuracy: 0.9992 - val_loss: 0.8581 - val_accuracy: 0.8276\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0317 - accuracy: 0.9988 - val_loss: 0.8901 - val_accuracy: 0.8266\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0307 - accuracy: 0.9989 - val_loss: 0.8899 - val_accuracy: 0.8258\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0302 - accuracy: 0.9989 - val_loss: 0.8596 - val_accuracy: 0.8292\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0291 - accuracy: 0.9990 - val_loss: 0.8479 - val_accuracy: 0.8316\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0258 - accuracy: 0.9995 - val_loss: 0.8958 - val_accuracy: 0.8214\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 162s 230ms/step - loss: 0.0248 - accuracy: 0.9997 - val_loss: 0.8349 - val_accuracy: 0.8310\n",
            "Training Time For ResNet-18 Using ReLU: 1:21:27.453080\n",
            "Training Of ResNet-18 Using ELU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 169s 234ms/step - loss: 2.7942 - accuracy: 0.3002 - val_loss: 2.1455 - val_accuracy: 0.3284\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 1.6851 - accuracy: 0.4584 - val_loss: 1.6685 - val_accuracy: 0.4512\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 1.3745 - accuracy: 0.5588 - val_loss: 1.7316 - val_accuracy: 0.4686\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 1.1665 - accuracy: 0.6205 - val_loss: 1.3568 - val_accuracy: 0.5696\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 1.0149 - accuracy: 0.6734 - val_loss: 1.2354 - val_accuracy: 0.6040\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 0.8973 - accuracy: 0.7126 - val_loss: 1.2505 - val_accuracy: 0.6020\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 0.7975 - accuracy: 0.7426 - val_loss: 0.9065 - val_accuracy: 0.7122\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 0.7176 - accuracy: 0.7688 - val_loss: 0.8531 - val_accuracy: 0.7234\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.6535 - accuracy: 0.7903 - val_loss: 0.7921 - val_accuracy: 0.7440\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.5900 - accuracy: 0.8110 - val_loss: 0.7870 - val_accuracy: 0.7430\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.5392 - accuracy: 0.8292 - val_loss: 0.8124 - val_accuracy: 0.7418\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 0.4951 - accuracy: 0.8432 - val_loss: 0.7046 - val_accuracy: 0.7812\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.4524 - accuracy: 0.8585 - val_loss: 0.8809 - val_accuracy: 0.7298\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.4160 - accuracy: 0.8707 - val_loss: 0.6548 - val_accuracy: 0.7942\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 0.3775 - accuracy: 0.8836 - val_loss: 0.7280 - val_accuracy: 0.7718\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 163s 232ms/step - loss: 0.3462 - accuracy: 0.8942 - val_loss: 0.6584 - val_accuracy: 0.8002\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.3126 - accuracy: 0.9067 - val_loss: 0.6641 - val_accuracy: 0.7914\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.2863 - accuracy: 0.9162 - val_loss: 0.6405 - val_accuracy: 0.8006\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.2600 - accuracy: 0.9264 - val_loss: 0.6898 - val_accuracy: 0.7904\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.2370 - accuracy: 0.9335 - val_loss: 0.7301 - val_accuracy: 0.7824\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.2146 - accuracy: 0.9416 - val_loss: 0.6400 - val_accuracy: 0.8108\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.1951 - accuracy: 0.9480 - val_loss: 0.6902 - val_accuracy: 0.8058\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.1755 - accuracy: 0.9559 - val_loss: 0.6850 - val_accuracy: 0.8134\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.1581 - accuracy: 0.9624 - val_loss: 0.6292 - val_accuracy: 0.8258\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.1428 - accuracy: 0.9684 - val_loss: 0.7661 - val_accuracy: 0.7952\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.1276 - accuracy: 0.9742 - val_loss: 0.6760 - val_accuracy: 0.8196\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.1160 - accuracy: 0.9770 - val_loss: 0.6642 - val_accuracy: 0.8268\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.1051 - accuracy: 0.9809 - val_loss: 0.7110 - val_accuracy: 0.8158\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 164s 232ms/step - loss: 0.0954 - accuracy: 0.9838 - val_loss: 0.7180 - val_accuracy: 0.8160\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 164s 233ms/step - loss: 0.0857 - accuracy: 0.9873 - val_loss: 0.7526 - val_accuracy: 0.8156\n",
            "Training Time For ResNet-18 Using ELU: 1:21:55.957091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQKV5vyzSu7D"
      },
      "source": [
        "#### VGG-16 Implementation For CIFAR-10 (Using Colab Pro)\n",
        "ReLU Timing: 1 h 1 min 28.50s\n",
        "\n",
        "ReLU Accuracy: 0.8524\n",
        "\n",
        "ELU Timing: 1 h 02 min 50.60s\n",
        "\n",
        "ELU Accuracy: 0.8636"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBzuXMq_tkSl",
        "outputId": "78d8cebc-9973-4abd-fe6e-a822cb24293b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Of VGG-16 Using ReLU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 127s 175ms/step - loss: 5.2095 - accuracy: 0.2705 - val_loss: 3.9431 - val_accuracy: 0.1058\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 2.7521 - accuracy: 0.3420 - val_loss: 3.3658 - val_accuracy: 0.1572\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 2.4313 - accuracy: 0.3721 - val_loss: 3.2042 - val_accuracy: 0.1524\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 2.2963 - accuracy: 0.4114 - val_loss: 2.2444 - val_accuracy: 0.4568\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 2.1315 - accuracy: 0.5547 - val_loss: 2.2351 - val_accuracy: 0.5528\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.9370 - accuracy: 0.6469 - val_loss: 1.9402 - val_accuracy: 0.6494\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.7848 - accuracy: 0.6960 - val_loss: 1.6967 - val_accuracy: 0.7202\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.6732 - accuracy: 0.7315 - val_loss: 1.7259 - val_accuracy: 0.7100\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.5776 - accuracy: 0.7614 - val_loss: 1.5721 - val_accuracy: 0.7638\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.4909 - accuracy: 0.7820 - val_loss: 1.5050 - val_accuracy: 0.7776\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.4202 - accuracy: 0.8029 - val_loss: 1.4315 - val_accuracy: 0.7978\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.3503 - accuracy: 0.8196 - val_loss: 1.3976 - val_accuracy: 0.8028\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.2832 - accuracy: 0.8370 - val_loss: 1.3549 - val_accuracy: 0.8124\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 123s 175ms/step - loss: 1.2273 - accuracy: 0.8487 - val_loss: 1.2978 - val_accuracy: 0.8254\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.1756 - accuracy: 0.8638 - val_loss: 1.2746 - val_accuracy: 0.8348\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.1287 - accuracy: 0.8735 - val_loss: 1.2692 - val_accuracy: 0.8254\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.0887 - accuracy: 0.8828 - val_loss: 1.2124 - val_accuracy: 0.8426\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.0478 - accuracy: 0.8944 - val_loss: 1.1780 - val_accuracy: 0.8496\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 1.0048 - accuracy: 0.9017 - val_loss: 1.1717 - val_accuracy: 0.8448\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.9698 - accuracy: 0.9085 - val_loss: 1.1311 - val_accuracy: 0.8552\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.9334 - accuracy: 0.9162 - val_loss: 1.1094 - val_accuracy: 0.8574\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.9057 - accuracy: 0.9224 - val_loss: 1.1164 - val_accuracy: 0.8496\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.8806 - accuracy: 0.9253 - val_loss: 1.0846 - val_accuracy: 0.8562\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.8443 - accuracy: 0.9323 - val_loss: 1.0559 - val_accuracy: 0.8632\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.8174 - accuracy: 0.9375 - val_loss: 1.0602 - val_accuracy: 0.8556\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.7972 - accuracy: 0.9393 - val_loss: 1.0361 - val_accuracy: 0.8646\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.7728 - accuracy: 0.9434 - val_loss: 1.0271 - val_accuracy: 0.8638\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.7508 - accuracy: 0.9467 - val_loss: 1.0286 - val_accuracy: 0.8592\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.7297 - accuracy: 0.9483 - val_loss: 1.0285 - val_accuracy: 0.8528\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 123s 174ms/step - loss: 0.7076 - accuracy: 0.9517 - val_loss: 1.0258 - val_accuracy: 0.8524\n",
            "Training Time For VGG-16 Using ReLU: 1:01:28.497404\n",
            "Training Of VGG-16 Using ELU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 129s 178ms/step - loss: 5.0605 - accuracy: 0.2793 - val_loss: 4.3275 - val_accuracy: 0.1074\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 125s 178ms/step - loss: 2.6885 - accuracy: 0.3438 - val_loss: 3.3136 - val_accuracy: 0.2046\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 125s 178ms/step - loss: 2.4248 - accuracy: 0.4196 - val_loss: 2.9174 - val_accuracy: 0.3078\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 2.2371 - accuracy: 0.5448 - val_loss: 2.3561 - val_accuracy: 0.4892\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 2.0156 - accuracy: 0.6067 - val_loss: 2.1538 - val_accuracy: 0.5606\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.8434 - accuracy: 0.6628 - val_loss: 1.9192 - val_accuracy: 0.6314\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.6969 - accuracy: 0.7041 - val_loss: 2.0952 - val_accuracy: 0.5866\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.5895 - accuracy: 0.7331 - val_loss: 1.7081 - val_accuracy: 0.6952\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.4973 - accuracy: 0.7615 - val_loss: 1.7307 - val_accuracy: 0.6866\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.4155 - accuracy: 0.7853 - val_loss: 1.4837 - val_accuracy: 0.7592\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 125s 178ms/step - loss: 1.3355 - accuracy: 0.8038 - val_loss: 1.3587 - val_accuracy: 0.7956\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 125s 178ms/step - loss: 1.2646 - accuracy: 0.8230 - val_loss: 1.3185 - val_accuracy: 0.8036\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.2014 - accuracy: 0.8392 - val_loss: 1.2614 - val_accuracy: 0.8108\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 126s 179ms/step - loss: 1.1428 - accuracy: 0.8556 - val_loss: 1.2085 - val_accuracy: 0.8310\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.0891 - accuracy: 0.8664 - val_loss: 1.2906 - val_accuracy: 0.8048\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 1.0428 - accuracy: 0.8761 - val_loss: 1.1741 - val_accuracy: 0.8368\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 126s 179ms/step - loss: 0.9967 - accuracy: 0.8882 - val_loss: 1.1609 - val_accuracy: 0.8358\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.9581 - accuracy: 0.8937 - val_loss: 1.1098 - val_accuracy: 0.8472\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.9186 - accuracy: 0.9058 - val_loss: 1.0897 - val_accuracy: 0.8432\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.8853 - accuracy: 0.9115 - val_loss: 1.1165 - val_accuracy: 0.8350\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.8498 - accuracy: 0.9186 - val_loss: 1.0959 - val_accuracy: 0.8448\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.8222 - accuracy: 0.9235 - val_loss: 1.0397 - val_accuracy: 0.8498\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.7899 - accuracy: 0.9308 - val_loss: 1.0087 - val_accuracy: 0.8558\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.7621 - accuracy: 0.9350 - val_loss: 1.0238 - val_accuracy: 0.8476\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.7427 - accuracy: 0.9362 - val_loss: 1.0099 - val_accuracy: 0.8508\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.7174 - accuracy: 0.9409 - val_loss: 0.9901 - val_accuracy: 0.8580\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.6939 - accuracy: 0.9447 - val_loss: 0.9846 - val_accuracy: 0.8500\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.6827 - accuracy: 0.9441 - val_loss: 0.9637 - val_accuracy: 0.8538\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.6556 - accuracy: 0.9494 - val_loss: 0.9976 - val_accuracy: 0.8442\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 126s 178ms/step - loss: 0.6366 - accuracy: 0.9522 - val_loss: 0.8958 - val_accuracy: 0.8676\n",
            "Training Time For VGG-16 Using ELU: 1:02:50.607803\n"
          ]
        }
      ],
      "source": [
        "class VGG16:\n",
        "\n",
        "  def __init__(self, inputShape=(32,32,3), weightDecay = 0.0005, activationFunction='elu'):\n",
        "    self.inputShape = inputShape\n",
        "    self.weightDecay = weightDecay\n",
        "    self.activationFunction = activationFunction\n",
        "\n",
        "  def buildModel(self):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Input(shape=input_shape))\n",
        "    model.add(tf.keras.layers.Resizing(224, 224))\n",
        "\n",
        "    # Input Block\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.L2(self.weightDecay)))\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "    self.ConvolutionBlock(model, 64)\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.ConvolutionBlock(model, 128, 0.4)\n",
        "    self.ConvolutionBlock(model, 128)\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.ConvolutionBlock(model, 256, 0.4)\n",
        "    self.ConvolutionBlock(model, 256, 0.4)\n",
        "    self.ConvolutionBlock(model, 256)\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.ConvolutionBlock(model, 512, 0.4)\n",
        "    self.ConvolutionBlock(model, 512, 0.4)\n",
        "    self.ConvolutionBlock(model, 512)\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    self.ConvolutionBlock(model, 512, 0.4)\n",
        "    self.ConvolutionBlock(model, 512, 0.4)\n",
        "    self.ConvolutionBlock(model, 512)\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(512,kernel_regularizer=tf.keras.regularizers.L2(self.weightDecay)))\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(10))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def ConvolutionBlock(self, model, filter, dropout=0):\n",
        "    model.add(tf.keras.layers.Conv2D(filter, (3, 3), padding='same',kernel_regularizer=tf.keras.regularizers.L2(self.weightDecay)))\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    if dropout != 0:\n",
        "      model.add(tf.keras.layers.Dropout(dropout))\n",
        "\n",
        "VGGInstance = VGG16(activationFunction = 'relu')\n",
        "VGGReluModel = VGGInstance.buildModel()\n",
        "VGGReluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm = 1, decay=0.005), metrics=['accuracy'])\n",
        "\n",
        "VGGInstance = VGG16(activationFunction = 'elu')\n",
        "VGGEluModel = VGGInstance.buildModel()\n",
        "VGGEluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm = 1, decay=0.005), metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of VGG-16 Using ReLU Activation Function\")\n",
        "VGGReluModelLog = VGGReluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For VGG-16 Using ReLU: %s' % (datetime.datetime.now() - startTime))\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of VGG-16 Using ELU Activation Function\")\n",
        "VGGEluModelLog = VGGEluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For VGG-16 Using ELU: %s' % (datetime.datetime.now() - startTime))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIUy-_BuSLpx"
      },
      "source": [
        "#### AlexNet Implementation For CIFAR-10 (Using Colab Pro)\n",
        "ReLU Timing: 32 min 24.64s\n",
        "\n",
        "ReLU Accuracy: 0.8450\n",
        "\n",
        "ELU Timing: 32 min 15.08s\n",
        "\n",
        "ELU Accuracy: 0.8336"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFCKnshXBjDh",
        "outputId": "4f74dfbf-95a3-47e0-8e04-e431477d04ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Of AlexNet Using ReLU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 67s 91ms/step - loss: 1.3691 - accuracy: 0.5264 - val_loss: 1.1720 - val_accuracy: 0.6074\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.9476 - accuracy: 0.6852 - val_loss: 0.9194 - val_accuracy: 0.6934\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.7445 - accuracy: 0.7559 - val_loss: 0.8056 - val_accuracy: 0.7284\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.6108 - accuracy: 0.8017 - val_loss: 0.6738 - val_accuracy: 0.7732\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.4991 - accuracy: 0.8389 - val_loss: 0.6393 - val_accuracy: 0.7852\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.3995 - accuracy: 0.8705 - val_loss: 0.6040 - val_accuracy: 0.8084\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.3103 - accuracy: 0.9031 - val_loss: 0.5956 - val_accuracy: 0.8158\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.2403 - accuracy: 0.9246 - val_loss: 0.5891 - val_accuracy: 0.8168\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.1836 - accuracy: 0.9451 - val_loss: 0.6055 - val_accuracy: 0.8156\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.1434 - accuracy: 0.9576 - val_loss: 0.6706 - val_accuracy: 0.8056\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.1203 - accuracy: 0.9638 - val_loss: 0.6573 - val_accuracy: 0.8160\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.1119 - accuracy: 0.9666 - val_loss: 0.6288 - val_accuracy: 0.8228\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0865 - accuracy: 0.9747 - val_loss: 0.6355 - val_accuracy: 0.8294\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0765 - accuracy: 0.9771 - val_loss: 0.6966 - val_accuracy: 0.8186\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.0758 - accuracy: 0.9776 - val_loss: 0.6203 - val_accuracy: 0.8328\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0606 - accuracy: 0.9826 - val_loss: 0.6559 - val_accuracy: 0.8256\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.0615 - accuracy: 0.9823 - val_loss: 0.6548 - val_accuracy: 0.8260\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0521 - accuracy: 0.9849 - val_loss: 0.6804 - val_accuracy: 0.8276\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.0531 - accuracy: 0.9845 - val_loss: 0.6539 - val_accuracy: 0.8326\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.0451 - accuracy: 0.9869 - val_loss: 0.6829 - val_accuracy: 0.8306\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.0469 - accuracy: 0.9858 - val_loss: 0.7119 - val_accuracy: 0.8364\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0392 - accuracy: 0.9886 - val_loss: 0.6978 - val_accuracy: 0.8254\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 0.6642 - val_accuracy: 0.8364\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 0.6655 - val_accuracy: 0.8386\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.0329 - accuracy: 0.9904 - val_loss: 0.7766 - val_accuracy: 0.8242\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.7184 - val_accuracy: 0.8352\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0283 - accuracy: 0.9920 - val_loss: 0.6839 - val_accuracy: 0.8426\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0314 - accuracy: 0.9908 - val_loss: 0.7556 - val_accuracy: 0.8290\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 63s 90ms/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 0.7342 - val_accuracy: 0.8322\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 64s 90ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.6754 - val_accuracy: 0.8450\n",
            "Training Time For AlexNet Using ReLU: 0:32:24.645190\n",
            "Training Of AlexNet Using ELU Activation Function\n",
            "Epoch 1/30\n",
            "704/704 [==============================] - 66s 91ms/step - loss: 1.4203 - accuracy: 0.5037 - val_loss: 1.2820 - val_accuracy: 0.5676\n",
            "Epoch 2/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 1.0633 - accuracy: 0.6406 - val_loss: 0.9433 - val_accuracy: 0.6826\n",
            "Epoch 3/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.8983 - accuracy: 0.6945 - val_loss: 0.8497 - val_accuracy: 0.7144\n",
            "Epoch 4/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.7901 - accuracy: 0.7328 - val_loss: 0.7684 - val_accuracy: 0.7420\n",
            "Epoch 5/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.7071 - accuracy: 0.7620 - val_loss: 0.7340 - val_accuracy: 0.7474\n",
            "Epoch 6/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.6248 - accuracy: 0.7884 - val_loss: 0.7120 - val_accuracy: 0.7562\n",
            "Epoch 7/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.5546 - accuracy: 0.8156 - val_loss: 0.6394 - val_accuracy: 0.7868\n",
            "Epoch 8/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.4925 - accuracy: 0.8374 - val_loss: 0.6681 - val_accuracy: 0.7826\n",
            "Epoch 9/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.4275 - accuracy: 0.8572 - val_loss: 0.5981 - val_accuracy: 0.7956\n",
            "Epoch 10/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.3659 - accuracy: 0.8801 - val_loss: 0.5796 - val_accuracy: 0.8102\n",
            "Epoch 11/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.3114 - accuracy: 0.8997 - val_loss: 0.5727 - val_accuracy: 0.8154\n",
            "Epoch 12/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.2540 - accuracy: 0.9201 - val_loss: 0.6008 - val_accuracy: 0.8128\n",
            "Epoch 13/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.2214 - accuracy: 0.9307 - val_loss: 0.5946 - val_accuracy: 0.8220\n",
            "Epoch 14/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.1929 - accuracy: 0.9375 - val_loss: 0.6262 - val_accuracy: 0.8126\n",
            "Epoch 15/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.1519 - accuracy: 0.9528 - val_loss: 0.6450 - val_accuracy: 0.8082\n",
            "Epoch 16/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.1368 - accuracy: 0.9588 - val_loss: 0.6238 - val_accuracy: 0.8226\n",
            "Epoch 17/30\n",
            "704/704 [==============================] - 64s 92ms/step - loss: 0.1120 - accuracy: 0.9668 - val_loss: 0.6570 - val_accuracy: 0.8064\n",
            "Epoch 18/30\n",
            "704/704 [==============================] - 64s 92ms/step - loss: 0.1108 - accuracy: 0.9665 - val_loss: 0.6024 - val_accuracy: 0.8224\n",
            "Epoch 19/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0935 - accuracy: 0.9729 - val_loss: 0.6490 - val_accuracy: 0.8168\n",
            "Epoch 20/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0828 - accuracy: 0.9747 - val_loss: 0.6679 - val_accuracy: 0.8200\n",
            "Epoch 21/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0761 - accuracy: 0.9773 - val_loss: 0.6255 - val_accuracy: 0.8272\n",
            "Epoch 22/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0770 - accuracy: 0.9764 - val_loss: 0.6689 - val_accuracy: 0.8188\n",
            "Epoch 23/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0669 - accuracy: 0.9808 - val_loss: 0.6487 - val_accuracy: 0.8218\n",
            "Epoch 24/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0690 - accuracy: 0.9802 - val_loss: 0.6791 - val_accuracy: 0.8198\n",
            "Epoch 25/30\n",
            "704/704 [==============================] - 64s 91ms/step - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.6825 - val_accuracy: 0.8266\n",
            "Epoch 26/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0580 - accuracy: 0.9823 - val_loss: 0.7205 - val_accuracy: 0.8176\n",
            "Epoch 27/30\n",
            "704/704 [==============================] - 64s 92ms/step - loss: 0.0427 - accuracy: 0.9882 - val_loss: 0.6536 - val_accuracy: 0.8238\n",
            "Epoch 28/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0518 - accuracy: 0.9840 - val_loss: 0.6898 - val_accuracy: 0.8260\n",
            "Epoch 29/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.6709 - val_accuracy: 0.8308\n",
            "Epoch 30/30\n",
            "704/704 [==============================] - 65s 92ms/step - loss: 0.0468 - accuracy: 0.9861 - val_loss: 0.6742 - val_accuracy: 0.8336\n",
            "Training Time For AlexNet Using ELU: 0:32:15.084036\n"
          ]
        }
      ],
      "source": [
        "class AlexNet:\n",
        "\n",
        "  def __init__(self, inputShape=(32,32,3), activationFunction='relu'):\n",
        "    self.inputShape = inputShape\n",
        "    self.activationFunction = activationFunction\n",
        "\n",
        "  def buildModel(self):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Resizing(224, 224))\n",
        "\n",
        "    # Convolutional Layer 1\n",
        "    model.add(tf.keras.layers.Conv2D(filters=96, input_shape=self.inputShape, kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # Convolutional Layer 2\n",
        "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "    # Convolutional Layer 3\n",
        "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "\n",
        "    # Convolutional Layer 4\n",
        "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "\n",
        "    # Convolutional Layer 5\n",
        "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "    #Pass To Fully Connected layer\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    # Fully Connected Layer 1\n",
        "    model.add(tf.keras.layers.Dense(4096, input_shape=self.inputShape))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    # Fully Connected Layer 2\n",
        "    model.add(tf.keras.layers.Dense(4096))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    # Fully Connected Layer 3\n",
        "    model.add(tf.keras.layers.Dense(1000))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation(self.activationFunction))\n",
        "    model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "    #Output Layer\n",
        "    model.add(tf.keras.layers.Dense(10))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "AlexNetInstance = AlexNet(activationFunction = 'relu')\n",
        "AlexNetReluModel = AlexNetInstance.buildModel()\n",
        "AlexNetReluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "AlexNetInstance = AlexNet(activationFunction = 'elu')\n",
        "AlexNetEluModel = AlexNetInstance.buildModel()\n",
        "AlexNetEluModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 30\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of AlexNet Using ReLU Activation Function\")\n",
        "AlexNetReluModelLog = AlexNetReluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For AlexNet Using ReLU: %s' % (datetime.datetime.now() - startTime))\n",
        "\n",
        "startTime = datetime.datetime.now()\n",
        "print(\"Training Of AlexNet Using ELU Activation Function\")\n",
        "AlexNetEluModelLog = AlexNetEluModel.fit(x_train, y_train,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      validation_split = 0.1,\n",
        "                     )\n",
        "print('Training Time For AlexNet Using ELU: %s' % (datetime.datetime.now() - startTime))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eZDpJYCzHfJc",
        "1bnVETOhRUuA",
        "OXocNuc3EOTz",
        "h1id5ID_RMaO",
        "yQKV5vyzSu7D",
        "eIUy-_BuSLpx"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}